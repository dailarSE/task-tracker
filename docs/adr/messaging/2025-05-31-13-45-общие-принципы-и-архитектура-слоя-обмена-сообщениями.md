# ADR-0035: Общие Принципы и Архитектура Слоя Обмена Сообщениями

*   **Статус:** Accepted
*   **Дата:** 2025-05-31
*   **Связанные ADR:**
    *   ADR-0001: Выбор Java/Spring Boot и ориентация на микросервисный подход
    *   ADR-0003: Внедрение комплексного стека обсервабилити
    *   ADR-0022: Управление Конфигурационными Свойствами и Безопасность Секретов
    *   ADR-0028: Обновленная Стратегия Обсервабилити
*   **Контекст:**
    *   Проект "Task Tracker" ориентирован на микросервисную архитектуру (ADR-0001), что подразумевает необходимость в механизмах асинхронного взаимодействия и слабой связанности между компонентами и будущими сервисами.
    *   Техническое задание проекта требует использования брокера сообщений Apache Kafka для реализации асинхронных операций, таких как отправка email-уведомлений.
    *   Требуется определить основополагающие принципы, технологии и стандарты для слоя обмена сообщениями, применимые ко всем сервисам проекта, для обеспечения консистентности, надежности, масштабируемости и анализа применимости различных подходов к интеграции с Kafka.

*   **Принятое Решение:**

    1.  **Основная Технология Брокера Сообщений:**
        *   В качестве основного и единственного брокера сообщений для межсервисного взаимодействия и реализации асинхронных потоков данных в проекте "Task Tracker" выбирается **Apache Kafka**.
        *   **Обоснование:** Высокая производительность, масштабируемость, отказоустойчивость, развитая экосистема, соответствие учебным целям проекта и требованиям ТЗ.
        *   **1.1. Режим Работы Kafka Кластера:**
            *   Для локальной разработки (через Docker Compose) и для будущих production-развертываний **предпочтительным является использование Kafka в режиме KRaft (Kafka Raft metadata mode)**, который устраняет зависимость от Apache ZooKeeper.
            *   Текущая конфигурация Docker Compose для разработки уже использует Kafka в режиме KRaft.
            *   Этот выбор влияет на инфраструктуру и управление самим Kafka-кластером, но для клиентов Kafka (продюсеров/консьюмеров), взаимодействие с брокером остается стандартным через `bootstrap.servers`.

    2.  **Библиотека Интеграции с Kafka для Приложений Spring Boot:**
        *   На начальном этапе разработки и для задач, требующих анализа применимости и детального контроля над взаимодействием с Kafka API (например, первоначальная настройка продюсера в `task-tracker-backend`), будет использоваться библиотека **`spring-kafka`** (`KafkaTemplate` для продюсеров, `@KafkaListener` для консьюмеров).
        *   **Обоснование:** `spring-kafka` предоставляет глубокую интеграцию с Kafka, позволяет детально конфигурировать клиентов и анализировать особенности их работы.
        *   **Перспектива:** Использование **Spring Cloud Stream (SCS) с Kafka Binder** будет рассмотрено на последующих этапах или для специфичных сервисов, где его высокоуровневые абстракции могут быть более предпочтительны.

    3.  **Формат Сообщений (Payload):**
        *   **Начальный стандарт:** **JSON**.
        *   **Обоснование:** Простота реализации, читаемость, наличие готовых DTO в Java, легкость отладки на начальных этапах.
        *   **Сериализация/Десериализация:** Стандартные `JsonSerializer` и `JsonDeserializer` из `spring-kafka` с использованием `Jackson2JsonObjectMapper`. Конфигурация "trusted packages" для `JsonDeserializer` обязательна.
        *   **Перспектива (особенно для доменных событий):** Переход на бинарные форматы (например, **Apache Avro**) с использованием **Schema Registry** будет рассмотрен при увеличении количества типов сообщений, необходимости строгой типизации, управления эволюцией схем и требований к производительности/компактности сообщений.

    4.  **Именование Топиков Kafka:**
        *   Применяется следующая конвенция именования: `<project_prefix>.<domain_or_context>.<message_type_or_entity>.[v<version>].<purpose_or_event_name>` (например, `task_tracker.notifications.email_commands`, `task_tracker.domain_events.task.v1.created`).
        *   Для Dead Letter Topics (DLT) используется суффикс `.DLT` к имени основного топика.

    5.  **Создание Топиков Kafka:**
        *   **Для `production` (и `staging`) окружений:** Топики **ДОЛЖНЫ** создаваться и конфигурироваться административно перед развертыванием приложений. Автоматическое создание топиков в production запрещено.

    6.  **Конфигурация Репликации Топиков в Production:**
        *   **Фактор Репликации (`replication-factor`):** Для всех топиков Kafka в **production-окружении** **ДОЛЖЕН** быть установлен `replication-factor` **не менее 3**.
        *   **Минимальное Количество Синхронизированных Реплик (`min.insync.replicas`):** Для топиков в **production-окружении** с `replication-factor=3`, параметр `min.insync.replicas` **ДОЛЖЕН** быть установлен в **2**.
        *   **Кластер Kafka:** Production-окружение **ДОЛЖНО** использовать кластер Kafka, состоящий как минимум из **3 брокеров**.

    7.  **Семантики Доставки Сообщений:**
        *   Выбор семантики доставки (`at-most-once`, `at-least-once`, `exactly-once`) **определяется индивидуально для каждого конкретного сценария публикации** и документируется в ADR, описывающих соответствующие компоненты-продюсеры.
        *   **Общие рекомендации:** `at-least-once` как базовая, `exactly-once` (через идемпотентного продюсера) для критичных данных/событий.
        *   Kafka Transactions рассматриваются для сценариев, требующих атомарности нескольких операций с Kafka или "БД+Kafka".

    8.  **Атомарность Операций "БД + Сообщение" и Идемпотентность Обработки:**
        *   **Паттерн Outbox (для Продюсеров):** Для критически важных сценариев, где необходимо гарантировать атомарную запись изменения в БД и последующую публикацию сообщения, **РЕКОМЕНДУЕТСЯ** использование паттерна Outbox. Решение о его внедрении принимается на этапе проектирования конкретного потока сообщений.
        *   **Паттерн Inbox (для Консьюмеров):** Для консьюмеров, обрабатывающих сообщения, где требуется идемпотентность, **РЕКОМЕНДУЕТСЯ** использование паттерна Inbox. Решение о его внедрении принимается на этапе проектирования консьюмера.

    9.  **Обработка Ошибок и Отказоустойчивость:**
        *   **Продюсеры:** Для асинхронной отправки сообщений и обработки результатов используется `CompletableFuture`, возвращаемый `org.springframework.kafka.core.KafkaTemplate`.
        *   **Консьюмеры:** Должны быть идемпотентными. Механизмы Retry и DLT должны применяться для обработки ошибок.

    10. **Наблюдаемость (Observability):**
        *   Все взаимодействия с Kafka **ДОЛЖНЫ** быть интегрированы с существующим стеком Observability (ADR-0028), включая сквозную трассировку, метрики и логирование.

    11. **Конфигурация Клиентов Kafka:**
        *   Параметры конфигурации управляются через `application.yml` и профили Spring Boot (ADR-0022).
        *   Для различных конфигураций продюсеров/консьюмеров в одном приложении определяются кастомные бины `ProducerFactory`/`ConsumerFactory` и `KafkaTemplate`/`ConcurrentKafkaListenerContainerFactory`.

*   **Рассмотренные Альтернативы (Уровень Фреймворка Интеграции):**
    *   **Исключительно Spring Cloud Stream (SCS) с самого начала:** Отложено для анализа применимости на основе опыта с `spring-kafka`.
    *   **Прямое использование нативного Kafka Clients API:** Отвергнуто в пользу удобства и интеграции `spring-kafka`.

*   **Последствия:**
    *   Заложена основа для асинхронной, событийно-ориентированной архитектуры.
    *   Стандартизирован подход к интеграции с Kafka.
    *   Учитываются аспекты надежности, отказоустойчивости и наблюдаемости.
    *   Определены направления для будущего развития (SCS, Avro, Outbox/Inbox).
## ADR-0001: Выбор Java/Spring Boot для бэкенда и ориентация на микросервисный подход

Использовать Java и Spring Boot для разработки бэкенд-сервисов. Проект будет развиваться с прицелом на микросервисную архитектуру. Использовать Maven для сборки.

## ADR-0002: Использование PostgreSQL в качестве основной реляционной СУБД

Использовать PostgreSQL

## ADR-0003: Внедрение комплексного стека обсервабилити (OTel, Prometheus, Grafana, Loki, Tempo)

Использовать OpenTelemetry (OTel) как стандарт для сбора телеметрии. Интегрировать стек: Prometheus для метрик, Loki для логов, Tempo для трейсов, Grafana для визуализации, OTel Collector для сбора и процессинга.

## ADR-0004: Использование Liquibase для управления миграциями базы данных

Использовать **Liquibase** в качестве инструмента для управления миграциями схемы базы данных. Миграции будут писаться в формате YAML и интегрироваться с жизненным циклом Spring Boot приложения, так что они будут автоматически применяться при старте приложения.

## ADR-0005: Определение Архитектуры Слоя Персистентности для Backend Сервисов

1.  **ORM и Стандарт:** Использовать **Jakarta Persistence API (JPA)** как стандарт для объектно-реляционного отображения. В качестве реализации JPA использовать **Hibernate**.
2.  **Доступ к данным:** Использовать **Spring Data JPA** для упрощения создания слоя доступа к данным (репозиториев).
3.  **Управление транзакциями:** Использовать декларативное управление транзакциями Spring (`@Transactional`).
4.  **Валидация сущностей:** Использовать аннотации **Jakarta Bean Validation** на полях JPA-сущностей.
5.  **Аудит временных меток:** Для полей, отслеживающих время создания и последнего обновления сущностей (например, `createdAt`, `updatedAt`):
    *   Тип данных `java.time.Instant` в Java-сущностях (соответствует `TIMESTAMPTZ` в PostgreSQL, согласно ADR-0011).
    *   Использовать аннотации **Hibernate (`@CreationTimestamp`, `@UpdateTimestamp`)**. Выбор в пользу аннотаций Hibernate сделан из-за их простоты и отсутствия необходимости в дополнительной конфигурации Spring Data JPA Auditing (`@EnableJpaAuditing`, `AuditorAware`), которая была бы избыточна для текущих требований простого аудита времени. Если в будущем потребуется аудит по пользователю (`@CreatedBy`, `@LastModifiedBy`), будет рассмотрен переход на полное решение Spring Data JPA Auditing.
6.  **Генерация первичных ключей:** По умолчанию для автоинкрементных первичных ключей использовать стратегию JPA **`@GeneratedValue(strategy = GenerationType.SEQUENCE)`** в сочетании с аннотацией **`@SequenceGenerator`**.
    *   Это обеспечивает получение ID до фактической вставки (`INSERT`) в базу данных, что полезно для снижения нагрузки на базу и/или для пакетных операций, где ID могут быть нужны заранее.
    *   Каждая сущность, требующая автогенерируемого ID, будет иметь свой собственный именованный sequence в базе данных (например, `users_id_seq`, `tasks_id_seq`), который будет создаваться через миграции Liquibase.
    *   Стратегия `GenerationType.IDENTITY` будет рассматриваться только в исключительных случаях, если для конкретной сущности она будет явно более подходящей и не будет ожидаться пакетных операций с предварительным получением ID.
7.  **Проверка соответствия схемы:** Настроить Hibernate на проверку соответствия JPA-сущностей схеме БД, созданной Liquibase, используя свойство `spring.jpa.hibernate.ddl-auto: validate`.

## ADR-0006: Использование Timestamp-based именования для файлов миграций Liquibase

Использовать **именование файлов миграций Liquibase на основе временной метки (timestamp-based naming)**.
Формат имени файла будет следующим: `YYYY-MM-DD-HH-MM-SS-краткое-описательное-имя.yaml`.
Например: `2025-05-09-10-30-00-create-users-table.yaml`.
Временная метка соответствует моменту создания (или коммита) файла миграции.

## ADR-0007: Использование структуры пакетов по доменам (фичам) в Backend сервисе

Использовать **организацию пакетов по доменам (фичам)** для бэкенд-сервиса `task-tracker-backend`.
Это означает, что пакеты верхнего уровня будут соответствовать основным бизнес-областям или функциональным возможностям системы. Например:
- `com.example.tasktracker.backend.user` (для всего, что связано с пользователями и аутентификацией)
- `com.example.tasktracker.backend.task` (для управления задачами)
- `com.example.tasktracker.backend.notification` (для отправки уведомлений)
Внутри каждого пакета домена компоненты могут быть сгруппированы по техническим слоям (например, `controller`, `service`, `entity`, `repository`, `dto`), но основной принцип группировки — принадлежность к фиче.
Также будут существовать общие пакеты на верхнем уровне для конфигураций и переиспользуемых компонентов, не относящихся к конкретному домену, например:
- `com.example.tasktracker.backend.config` (общие конфигурации Spring)
- `com.example.tasktracker.backend.common` (общие утилиты, исключения, модели)

## ADR-0008: Использование Testcontainers для интеграционных тестов базы данных

Использовать **Testcontainers** для проведения интеграционных тестов слоя персистентности (в частности, для тестирования Spring Data JPA репозиториев).
Testcontainers будут использоваться для запуска Docker-контейнера с PostgreSQL непосредственно из кода тестов. Каждый тестовый класс (или тестовый набор) будет работать с чистым, изолированным экземпляром базы данных. Интеграция со Spring Boot будет осуществляться с помощью `spring-boot-testcontainers` и аннотации `@ServiceConnection` для автоматической настройки `DataSource`.

## ADR-0009: Определение стратегии обсервабилити и выбор технологического стека

1.  **Стандарт и Протокол:** Принять **OpenTelemetry (OTel)** как основной стандарт для генерации, сбора и экспорта телеметрии (логов, метрик, трейсов). Использовать протокол OTLP для передачи данных.
2.  **Централизованный Сбор:** Использовать **OTel Collector** как центральный компонент для приема OTLP данных от приложений, их возможной обработки и экспорта в соответствующие бэкенды.
3.  **Бэкенды для Сигналов:**
    *   **Метрики:** **Prometheus** для сбора, хранения и запроса метрик.
    *   **Трейсы:** **Tempo** для сбора, хранения и запроса распределенных трейсов.
    *   **Логи:** **Loki** для сбора, хранения и запроса логов.
    *   **Визуализация:** **Grafana** для единого интерфейса визуализации метрик (из Prometheus), трейсов (из Tempo) и логов (из Loki).
	*   **Генерация Метрик из Трейсов (SPAN-метрики и Графы Сервисов):**
    *   **Tempo** (с использованием компонента `metrics_generator`) будет анализировать входящие трейсы для генерации агрегированных метрик (например, количество запросов, задержки, ошибки на уровне отдельных SPAN'ов или сервисов) и данных для построения графа зависимостей сервисов. Эти сгенерированные метрики будут отправляться из Tempo в **Prometheus** через механизм `remote_write`. Это позволяет получать RED-метрики (Rate, Errors, Duration) и строить карты сервисов автоматически на основе данных трассировки, дополняя метрики, собираемые непосредственно из приложений.
4.  **Инструментация Бэкенд-Приложений (Java/Spring Boot):**
    *   **Логирование:** SLF4J/Logback, настроенный на вывод структурированных логов в формате **JSON ECS**. Обеспечить включение `trace_id` и `span_id` (из OTel/Micrometer Tracing) в логи для корреляции. Логи будут собираться OTel Collector (либо через stdout, либо через OTel Logback Appender).
    *   **Метрики:** Micrometer API в приложении. Экспорт метрик через `micrometer-registry-otlp` в OTel Collector. Включение стандартных метрик Spring Boot Actuator и JVM, а также метрик пула соединений DataSource. Поощряется создание кастомных бизнес- и технических метрик.
    *   **Трассировка:** Micrometer Tracing с мостом к OpenTelemetry (`micrometer-tracing-bridge-otel`). Авто-инструментация для HTTP, JDBC. Обеспечение распространения контекста трассировки.
5.  **Инфраструктура для Локальной Разработки (`dev`):** Полный стек (OTel Collector, Prometheus, Tempo, Grafana, Loki) разворачивается через `docker-compose.yml` для максимальной детализации и отладки.
6.  **Конфигурация по Стендам (Профили Spring Boot):** Использовать профили (`dev`, `ci`, `prod`) для дифференцированной настройки обсервабилити:
    *   **`dev`:** Максимальная детализация. Все экспортеры OTel включены, 100% сэмплирование трейсов, подробные логи.
    *   **`ci`:** Фокус на диагностике тестов. OTel SDK и экспорт OTLP для метрик и трейсов **отключены** для экономии ресурсов и ускорения (`otel.sdk.disabled: true`). Логирование подробное (DEBUG уровни для приложения и SQL), формат JSON ECS, но без `trace_id`/`span_id` из-за отключенного OTel SDK.
    *   **`prod` (видение):** Фокус на мониторинге здоровья, SLI/SLO, алертинге. Сэмплирование трейсов, уровни логирования INFO/WARN, экспорт всех сигналов в выделенный, отказоустойчивый стек.
	
## ADR-0010: Выбор и конфигурация CI-сервера и агента для сборки и тестирования

1.  **CI-сервер:** Использовать **Jenkins**, развернутый в Docker-контейнере на основной VPS. Образ `jenkins/jenkins:lts-jdk21` (или аналогичный с нужной версией JDK).
2.  **Jenkins Агент:** Использовать **внешний Jenkins агент**, установленный и работающий непосредственно на **хост-машине VPS Ubuntu 22**.
    *   **Подключение к Master:** Агент подключается к Jenkins Master (в Docker) через JNLP (или WebSocket).
    *   **Метка Агента:** Агенту присвоена метка (label) `ubuntu-docker` для использования в `Jenkinsfile`.
    *   **Доступ к Docker:** Пользователь, от имени которого работает агент на VPS, добавлен в группу `docker`, что обеспечивает агенту прямой доступ к Docker-демону хост-машины. Это необходимо для запуска Testcontainers.
    *   **Управление:** Агент настроен как systemd сервис для автоматического запуска при старте VPS.
3.  **`Jenkinsfile`:** Пайплайн Jenkins определяется в `Jenkinsfile` в корне репозитория, используется декларативный синтаксис.
4.  **Профиль для CI:** В приложении Spring Boot используется профиль `ci` (`application-ci.yml`) для специфичных настроек во время выполнения на CI-агенте (например, уровни логирования, отключение OTel SDK).

## ADR-0011: Стратегия конфигурации локального dev-окружения с использованием Docker Compose и Spring Boot профилей

1.  **Инфраструктура через `docker-compose.yml`:** Все внешние зависимости для локальной разработки (PostgreSQL, Kafka, OTel Collector, Prometheus, Grafana, Loki, Tempo) определяются и запускаются через единый `docker-compose.yml` файл в корне проекта.
2.  **Spring Boot профиль `dev`:**
    *   Приложение `task-tracker-backend`, запущенное из IDE, использует профиль `dev` (активируется через VM Option `-Dspring.profiles.active=dev`).
    *   **`application-dev.yml`:**
        *   URL для подключения к PostgreSQL: `jdbc:postgresql://postgres:5432/task_tracker_db` (при наличии соответствующей записи в `hosts` файле, указывающей на `127.0.0.1`).
        *   Учетные данные для PostgreSQL (`spring.datasource.username`, `spring.datasource.password`): **Жестко прописаны** как `devuser` и `devpass`, чтобы соответствовать конфигурации PostgreSQL в `docker-compose.yml`.
        *   Включено детальное логирование SQL (`show-sql: true`, `format-sql: true`, уровни DEBUG/TRACE для Hibernate).
        *   OTel SDK включен, сэмплирование трейсов 100%.
        *   Эндпоинт OTel Collector для отправки телеметрии: `http://otel-collector:4318` (предполагая, что порт OTel Collector проброшен на хост).
3.  **Разрешение имен сервисов:** Для удобства подключения к сервисам, запущенным в Docker, из приложения на хосте (если используется имя сервиса, а не `localhost`), разработчики могут добавить соответствующие записи в свой локальный `hosts` файл (например, `127.0.0.1 postgres`, `127.0.0.1 otel-collector`).

## ADR-0012: Обеспечение консистентности времени через использование UTC во всех компонентах системы

1.  **Стандартный Часовой Пояс для Серверной Логики и Хранения:** Все серверные компоненты (приложение `task-tracker-backend`, база данных PostgreSQL, в будущем другие микросервисы) должны работать и хранить все временные метки в **UTC (Coordinated Universal Time)**.
2.  **Конфигурация JVM:** Для приложения `task-tracker-backend` при запуске из IDE (в `dev` профиле) и при выполнении тестов на CI-агенте (через Maven Surefire Plugin) будет установлена системная переменная JVM `-Duser.timezone=UTC`. *Примечание: Настройка для Docker-контейнера приложения отложена до этапа контейнеризации.*
3.  **Конфигурация Базы Данных (PostgreSQL):**
    *   Сервер PostgreSQL (запускаемый в Docker) по умолчанию инициализируется и работает в часовом поясе UTC. Это поведение будет сохранено.
    *   Для колонок, хранящих временные метки (например, `created_at`, `updated_at` в таблице `users`), используется тип данных **`TIMESTAMP WITH TIME ZONE` (TIMESTAMPTZ)**. В PostgreSQL этот тип данных хранит значение как момент времени в UTC, а при извлечении конвертирует его в часовой пояс сессии клиента (если он отличается).
4.  **Обработка времени в Java-коде:**
    *   Для представления моментов времени в Java-сущностях и DTO используется тип `java.time.Instant`, который всегда представляет собой точку на временной шкале UTC.
    *   Любые операции с датой/временем на сервере, требующие знания текущего момента, должны получать его как момент в UTC (например, через `@CreationTimestamp`, `@UpdateTimestamp` от Hibernate, которые работают с учетом часового пояса JVM, или `Instant.now()`).
5.  **Ответственность Фронтенда за Локальное Время Пользователя:**
    *   **Фронтенд-приложение несет ответственность за определение локального часового пояса пользователя.**
    *   При отправке любых данных, содержащих время, на бэкенд (например, дедлайн задачи), фронтенд должен **конвертировать это локальное время пользователя в UTC** и отправлять на бэкенд уже в UTC (например, в формате ISO 8601 с указанием `Z` или смещения +00:00).
    *   При получении данных от бэкенда (которые всегда будут в UTC), фронтенд несет ответственность за их конвертацию в локальный часовой пояс пользователя для корректного отображения.
	
## ADR-0013: Стандарты и подходы к документированию архитектурных решений и диаграмм

1.  **Architecture Decision Records (ADR):**
    *   **Назначение:** Для фиксации всех архитектурно значимых решений, их контекста, рассмотренных альтернатив и последствий.
    *   **Формат:** Markdown (`.md`).
    *   **Хранение:** В Git-репозитории, в директории `docs/adr/`.
    *   **Структура директорий ADR:** ADR группируются по тематическим поддиректориям (например, `common`, `backend-service`, `database`, `observability`, `ci-cd`, etc.) внутри `docs/adr/` для лучшей организации.
    *   **Именование файлов ADR:** Используется формат `YYYY-MM-DD-HH-MM-краткое-описательное-имя.md` (например, `2025-05-10-10-00-пример-решения.md`). Временная метка обеспечивает глобальную хронологию и уникальность.
    *   **Шаблон ADR:** Используется стандартный шаблон, включающий как минимум: Заголовок (с номером ADR), Статус, Дату, Контекст, Принятое Решение, Рассмотренные Альтернативы, Последствия. Номер ADR присваивается последовательно (например, ADR-0001, ADR-0002).
    *   **Процесс:** Решения обсуждаются командой; ответственный (обычно архитектор или тимлид) формулирует ADR; ADR может проходить неформальное ревью командой.
2.  **Архитектурные Диаграммы (C4 Model):**
    *   **Назначение:** Для визуализации архитектуры на различных уровнях абстракции (Контекст, Контейнеры, Компоненты).
    *   **Инструмент:** `draw.io` для создания и редактирования диаграмм.
    *   **Исходный формат:** Файлы `.drawio` (XML) сохраняются в Git.
    *   **Формат для публикации/документации:** Диаграммы экспортируются в формат **WebP (lossless)** для вставки в Markdown-документы (ADR, README).
    *   **Хранение:** Исходники (`.drawio`) и экспортированные изображения (`.webp`) хранятся в Git-репозитории в директории `docs/diagrams/`. Для детализирующих диаграмм используются поддиректории, соответствующие элементу верхнего уровня (например, `docs/diagrams/task-tracker-system/backend-api/`).
    *   **Именование файлов диаграмм:** `c4-L[Уровень]-описание.drawio` и `c4-L[Уровень]-описание.webp` (например, `c4-L1-system-context.webp`, `c4-L2-containers-task-tracker-system.webp`).
3.  **Файлы `README.md`:**
    *   **Корневой `README.md`:** Содержит общее описание проекта, инструкции по запуску, ссылки на ключевые разделы документации (включая ADR и диаграммы).
    *   **`README.md` на уровне модулей/сервисов:** Содержат специфичную информацию для данного модуля.
4.  **Confluence (или аналогичная Wiki):**
    *   Используется для хранения "живой" информации, не подходящей для Git: практические гайды, протоколы встреч (если не формализованы в ADR), информация о команде, общие процессы.
    *   Не используется для дублирования ADR или диаграмм, которые хранятся в Git. Может содержать обзорные страницы со ссылками на документацию в Git.

## ADR-0014: Процессы принятия архитектурных решений, управления задачами и работы с системой контроля версий

**2.1. Процесс Принятия и Документирования Архитектурных Решений (ADR):**
    *   **Идентификация:** Любой член команды может инициировать обсуждение архитектурно значимого вопроса. Тимлид или архитектор определяет, требует ли вопрос формализации в виде ADR.
    *   **Обсуждение:** Решение обсуждается командой (на встречах, в чате, в комментариях к задаче). Рассматриваются различные варианты.
    *   **Формулирование ADR:** Ответственный (обычно тимлид, архитектор или разработчик, глубоко вовлеченный в проблему) создает черновик ADR в соответствии с принятым шаблоном (см. ADR-0013).
    *   **Ревью ADR (неформальное):** Черновик ADR может быть рассмотрен другими членами команды для получения обратной связи.
    *   **Утверждение:** Решение и ADR считаются принятыми после согласования с тимлидом/архитектором. Статус ADR меняется на "Accepted".
    *   **Хранение:** ADR хранится в Git-репозитории в `docs/adr/` и версионируется вместе с кодом.
    *   **Обновление:** Принятые ADR не изменяются. Если решение пересматривается, создается новый ADR, который ссылается на старый и указывает его новый статус (Deprecated, Superseded).

**2.2. Формализация и Выделение Фич/Задач:**
    *   **Источник:** Требования (ТЗ, User Stories), технический долг, предложения по улучшению.
    *   **Декомпозиция:** Крупные фичи разбиваются на более мелкие, управляемые задачи (например, в Jira).
    *   **Приоритезация:** Задачи приоритезируются в рамках бэклога спринта/проекта.
    *   **Связь с ADR:** Если реализация задачи требует принятия архитектурно значимого решения, создается или обновляется соответствующий ADR.

**2.3. Правила Работы с Ветками (GitHub Flow - адаптированный):**
    *   **`main`:** Основная стабильная ветка. Всегда должна быть в состоянии, готовом к деплою (или отражать последний деплой). Прямые коммиты в `main` запрещены. Слияние только через Pull Request (PR) / Merge Request (MR).
    *   **Feature-ветки (`feature/название-фичи` или `feature/TTN-описание`):** Для каждой новой фичи, улучшения или значимой задачи создается отдельная ветка от актуального состояния `main`.
        *   Именование: `feature/TTN-kratkoe-opisanie` (где TTN - номер задачи в Jira, если используется) или `feature/kratkoe-opisanie-logicheskoy-celi`.
    *   **Bugfix-ветки (`bugfix/название-бага` или `bugfix/TTN-описание`):** Для исправления багов. Создаются от `main` (если баг в текущем релизе) или от соответствующей feature-ветки (если баг найден в ходе разработки фичи).
    *   **Hotfix-ветки (`hotfix/название-хотфикса`):** (Если потребуется для "боевых" ситуаций) Для срочных исправлений в продакшене. Создаются от тега релиза на `main`, мержуются обратно в `main` и в активные feature-ветки.
    *   **Регулярное обновление feature-веток:** Разработчики должны регулярно обновлять свои feature-ветки последними изменениями из `main`. Предпочтительно использовать `git rebase origin/main` для поддержания чистой и линейной истории коммитов в feature-ветке перед созданием PR. В случае сложных или длительных конфликтов при rebase, допустимо использовать `git merge origin/main` в feature-ветку.

**2.4. Правила для Коммитов:**
    *   **Атомарность:** Коммит должен представлять одно логическое изменение.
    *   **Сообщения коммитов:** Использовать стандарт Conventional Commits (например, `feat: ...`, `fix: ...`, `docs: ...`, `refactor: ...`, `test: ...`, `chore: ...`).
        *   Заголовок должен быть кратким и информативным.
        *   Тело коммита (если нужно) должно объяснять "что" и "почему", а не "как".
    *   **Частота:** Коммитить часто, небольшими порциями.

**2.5. Правила Слияния (Pull Request / Merge Request Workflow):**
    *   **Создание PR:** После завершения работы в feature/bugfix-ветке и локального тестирования, разработчик создает PR в `main`.
    *   **Описание PR:** PR должен иметь четкое описание проделанной работы, ссылки на задачи в Jira (если используются), инструкции по тестированию (если нужны).
    *   **CI-проверка:** Автоматический CI-пайплайн (Jenkins) должен успешно пройти для PR (сборка, все тесты).
    *   **Код-ревью:** Обязательное код-ревью как минимум одним другим членом команды (предпочтительно тимлид или другой senior-разработчик). Все замечания должны быть устранены.
    *   **Слияние:** После успешного CI и одобрения ревью, PR может быть смержен.
        *   **Метод слияния:** Предпочтительным методом является **"Rebase and merge"**. Это обеспечивает линейную историю коммитов в ветке `main`. Если `rebase` feature-ветки на `main` вызывает значительные или трудноразрешимые конфликты (например, из-за длительного существования ветки или большого количества пересекающихся изменений), в качестве альтернативы допустимо использовать **"Merge commit"** (со стандартным merge-коммитом, без squash).
    *   **Удаление ветки:** После мержа feature/bugfix-ветка удаляется из удаленного репозитория.

## ADR-0015: Стратегия и подходы к тестированию в проекте "Task Tracker"

**2.1. Юнит-тесты (Unit Tests):**
    *   **Цель:** Тестирование отдельных, изолированных компонентов (классов, методов) на корректность их логики.
    *   **Инструменты:** JUnit 5, Mockito.
    *   **Область применения:** Сервисный слой (бизнес-логика), утилитарные классы, отдельные сложные методы в контроллерах или других компонентах.
    *   **Изоляция:** Зависимости должны быть замоканы для обеспечения изоляции тестируемого юнита.
    *   **Скорость:** Должны быть очень быстрыми.
    *   **Запуск:** Выполняются на фазе `test` Maven плагином Surefire. Запускаются часто локально и всегда на CI.

**2.2. Интеграционные тесты (Integration Tests):**
    *   **Цель:** Тестирование взаимодействия между несколькими компонентами системы или интеграции с внешними зависимостями (база данных, брокеры сообщений, внешние API).
    *   **Типы интеграционных тестов (на текущем этапе и в ближайшем будущем):**
        *   **Тесты слоя персистентности:** Проверка корректности работы Spring Data JPA репозиториев и их взаимодействия с реальной базой данных.
            *   **Инструменты:** Spring Boot Test (`@SpringBootTest` или `@DataJpaTest`), Testcontainers (для PostgreSQL).
        *   **Тесты API/Контроллеров (когда появятся контроллеры):** Проверка работы REST API эндпоинтов, включая валидацию запросов, корректность ответов, обработку ошибок, интеграцию с сервисным слоем.
            *   **Инструменты:** Spring Boot Test (`@SpringBootTest` с `WebEnvironment.MOCK` или `RANDOM_PORT`), MockMvc или RestAssured. Testcontainers могут использоваться, если эндпоинты зависят от БД.
        *   **Тесты взаимодействия с Kafka (когда появится Kafka):** Проверка отправки и получения сообщений.
            *   **Инструменты:** Spring Boot Test, Embedded Kafka (для Spring Kafka) или Testcontainers для Kafka.
    *   **Скорость:** Медленнее юнит-тестов, так как требуют поднятия контекста Spring и/или внешних зависимостей.
    *   **Запуск:**
        *   **Локально:** Могут запускаться разработчиком по необходимости.
        *   **CI:** Обязательно выполняются на CI-сервере.
        *   **Maven:** Будут настроены для запуска плагином Failsafe на фазах `integration-test` и `verify`. Пока запускаются Surefire вместе с юнит-тестами.

**2.3. Контрактные тесты (Contract Tests - видение на будущее):**
    *   **Цель:** (Когда появятся несколько взаимодействующих микросервисов) Проверка соблюдения контрактов (API) между сервисами-провайдерами и сервисами-консьюмерами.
    *   **Инструменты:** Например, Spring Cloud Contract.
    *   **Статус:** На данном этапе не реализуются, но учитываются как возможный следующий шаг при развитии микросервисной архитектуры.

**2.4. End-to-End (E2E) тесты (видение на будущее):**
    *   **Цель:** Тестирование всей системы как "черного ящика" через пользовательский интерфейс (если он будет сложным) или через публичные API, имитируя реальные пользовательские сценарии.
    *   **Инструменты:** Selenium, Cypress, Playwright (для UI); Postman/Newman, Karate DSL (для API E2E).
    *   **Статус:** На данном этапе не реализуются.

**2.5. Покрытие Кода (Code Coverage):**
    *   **Цель:** Измерение процента кода, покрытого автоматическими тестами. Служит индикатором, но не самоцелью.
    *   **Инструменты:** JaCoCo (для Java).
    *   **Процесс:** Отчеты о покрытии будут генерироваться на CI и могут быть интегрированы в Jenkins для визуализации.
	
## ADR-0016: Конвенции и инструменты для интеграционного тестирования JPA и CI-отчетности

1.  **Именование интеграционных тестов:**
    *   Интеграционные тесты, предназначенные для выполнения Maven Failsafe Plugin, должны именоваться с использованием суффикса `IT`. Например: `UserRepositoryIT.java`. Это соответствует стандартным паттернам Failsafe и упрощает конфигурацию.

2.  **Тестирование слоя JPA (Репозитории):**
    *   Для интеграционных тестов компонентов слоя JPA (например, Spring Data JPA репозиториев) рекомендуется использовать аннотацию `@DataJpaTest`.
    *   Эта аннотация загружает сфокусированный срез контекста Spring, необходимый для JPA, автоматически настраивает транзакционность для тестовых методов (с откатом по умолчанию) и может использоваться совместно с Testcontainers (через `@ServiceConnection`) для тестирования на реальной СУБД.

3.  **Отчетность по результатам тестов в CI (Jenkins):**
    *   Jenkins пайплайн настроен на сбор и публикацию результатов юнит-тестов (выполняемых Surefire) и интеграционных тестов (выполняемых Failsafe).
    *   Для этого используется стандартный шаг `junit` в `Jenkinsfile`, который обрабатывает XML-отчеты, генерируемые Maven-плагинами.

4.  **Отчетность по покрытию кода в CI (Jenkins):**
    *   Для сбора данных о покрытии кода используется JaCoCo Maven Plugin, настроенный на сбор данных как от юнит-, так и от интеграционных тестов в единый файл `jacoco.exec`.
    *   Для публикации и визуализации отчетов о покрытии в Jenkins используется "coverage plugin" через шаг `recordCoverage` в `Jenkinsfile`. Пайплайн настроен на обработку XML-отчета `jacoco.xml`.